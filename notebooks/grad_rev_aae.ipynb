{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os, time, numbers, shutil\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch_optimizer as optim_ex\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.autograd import Function\n",
    "import random\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_info = torch.__config__.parallel_info()\n",
    "print(para_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "igpu = 0\n",
    "batch_size = 512\n",
    "lr = 0.01\n",
    "max_epoch = 2000\n",
    "\n",
    "n_coord_num = 3\n",
    "n_subclasses = 3\n",
    "nstyle = 2\n",
    "\n",
    "sch_factor = 0.25\n",
    "sch_patience = 300\n",
    "alpha_flat_step = 250\n",
    "alpha_limit = 1.0\n",
    "\n",
    "lr_ratio_Reconn = 2.0\n",
    "lr_ratio_Mutual = 3.0\n",
    "lr_ratio_Smooth = 0.1\n",
    "lr_ratio_Supervise = 2.0\n",
    "lr_ratio_Style = 0.5\n",
    "lr_ratio_CR = 0.5\n",
    "lr_ratio_domain = 1.0\n",
    "match_target_dist = True\n",
    "include_transfer_learning = True\n",
    "\n",
    "train_ratio = 0.7\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "sampling_exponent = 0.6\n",
    "\n",
    "variable_list_before_papermill_injection = set(locals().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_list_after_papermill_injection = set(locals().keys())\n",
    "excess_variables = variable_list_after_papermill_injection - variable_list_before_papermill_injection\n",
    "for v in list(excess_variables):\n",
    "    if v.startswith(\"_\"):\n",
    "        excess_variables.remove(v)\n",
    "excess_variables.remove(\"variable_list_before_papermill_injection\")\n",
    "assert len(excess_variables) == 0, f\"unexpected parameters:{excess_variables}\"   \n",
    "print(f\"This notebook will use GPU:{igpu} if available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feff_cn_spec_df = pd.read_csv(\"ti_feff_cn_spec.csv\", index_col=[0,1])\n",
    "n_feff_training_samples = int(len(feff_cn_spec_df) * train_ratio)\n",
    "n_feff_validation_samples = int(len(feff_cn_spec_df) * validation_ratio)\n",
    "n_feff_test_samples = len(feff_cn_spec_df) - n_feff_training_samples - n_feff_validation_samples\n",
    "assert math.fabs(n_feff_test_samples - int(len(feff_cn_spec_df) * test_ratio)) < 3\n",
    "cn_feff_nums =feff_cn_spec_df.to_numpy()[:n_feff_training_samples, :n_coord_num].sum(axis=0)\n",
    "print(\"Number of samples\", cn_feff_nums)\n",
    "cn_sampling_weights =  1.0 / feff_cn_spec_df.to_numpy()[:n_feff_training_samples, :n_coord_num].mean(axis=0)\n",
    "print(\"Raw sampling weights\", cn_sampling_weights)\n",
    "cn_sampling_weights **= sampling_exponent\n",
    "cn_sampling_weights /= cn_sampling_weights.sum()\n",
    "print(\"Sampling weights\", cn_sampling_weights)\n",
    "print(\"Sample numbers per epoch\", (cn_sampling_weights*cn_feff_nums * (cn_feff_nums.sum()/(cn_sampling_weights*cn_feff_nums).sum())).astype('int'))\n",
    "feff_cn_spec_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if include_transfer_learning:\n",
    "    xspectra_cn_spec_df = pd.read_csv(\"ti_xspectra_cn_spec.csv\", index_col=[0,1])\n",
    "    n_xspectra_training_samples = int(len(xspectra_cn_spec_df) * train_ratio)\n",
    "\n",
    "    n_xspectra_test_samples = len(xspectra_cn_spec_df) - n_xspectra_training_samples\n",
    "    assert math.fabs(n_xspectra_test_samples - int(len(xspectra_cn_spec_df) * (test_ratio+validation_ratio))) < 3\n",
    "    cn_xspectra_nums = xspectra_cn_spec_df.to_numpy()[:n_xspectra_training_samples, :n_coord_num].sum(axis=0)\n",
    "\n",
    "    print(\"XSpectra coord number counts\", cn_xspectra_nums)\n",
    "    print(\"FEFF coord number counts\", cn_feff_nums)\n",
    "    if match_target_dist:\n",
    "        domain_sampling_weights = cn_xspectra_nums / cn_feff_nums\n",
    "    else:\n",
    "        domain_sampling_weights = np.ones(n_coord_num)\n",
    "    domain_sampling_weights /= domain_sampling_weights.sum()\n",
    "    print(\"Domain sampling weights\", domain_sampling_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoordNumSpectraDataset(Dataset):\n",
    "    def __init__(self, df, n_coord_num=3, transform=None):\n",
    "        assert df.columns.to_list()[:n_coord_num+1] == ['CN_4', 'CN_5', 'CN_6', 'ENE_4965.000']\n",
    "        data = df.to_numpy()\n",
    "        self.cn = data[:, :n_coord_num]\n",
    "        self.spec = data[:, n_coord_num:]\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.cn.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        sample = self.spec[idx], self.cn[idx]\n",
    "        if self.transform is not None:\n",
    "            sample = [self.transform(x) for x in sample]\n",
    "        return sample\n",
    "    \n",
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        return torch.Tensor(sample)\n",
    "\n",
    "transform_list = transforms.Compose([ToTensor()])\n",
    "dataset_feff_train = CoordNumSpectraDataset(feff_cn_spec_df[:n_feff_training_samples], \n",
    "                                            n_coord_num=n_coord_num, transform=transform_list)\n",
    "dataset_feff_val = CoordNumSpectraDataset(feff_cn_spec_df[n_feff_training_samples:n_feff_training_samples+n_feff_validation_samples], \n",
    "                                          n_coord_num=n_coord_num, transform=transform_list)\n",
    "dataset_feff_test = CoordNumSpectraDataset(feff_cn_spec_df[-n_feff_test_samples:], \n",
    "                                           n_coord_num=n_coord_num, transform=transform_list)\n",
    "if include_transfer_learning:\n",
    "    dataset_xspectra_train = CoordNumSpectraDataset(xspectra_cn_spec_df[:n_xspectra_training_samples], \n",
    "                                                    n_coord_num=n_coord_num, transform=transform_list)\n",
    "    dataset_xspectra_test = CoordNumSpectraDataset(xspectra_cn_spec_df[-n_xspectra_test_samples:], \n",
    "                                                   n_coord_num=n_coord_num, transform=transform_list)\n",
    "    print(len(dataset_xspectra_train), len(dataset_xspectra_test))\n",
    "\n",
    "len(dataset_feff_train), len(dataset_feff_val), len(dataset_feff_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feff_train_max_cn_list = [np.argmax(dataset_feff_train[i][1].numpy()) for i in range(len(dataset_feff_train))]\n",
    "feff_val_max_cn_list = [np.argmax(dataset_feff_val[i][1].numpy()) for i in range(len(dataset_feff_val))]\n",
    "cn_train_sample_weights = [cn_sampling_weights[cn] for cn in feff_train_max_cn_list]\n",
    "if include_transfer_learning:\n",
    "    domain_train_sample_weights = [domain_sampling_weights[cn] for cn in feff_train_max_cn_list]\n",
    "cn_val_sample_weights = [cn_sampling_weights[cn] for cn in feff_val_max_cn_list]\n",
    "\n",
    "cn_train_sampler = WeightedRandomSampler(cn_train_sample_weights, replacement=True,\n",
    "                                         num_samples=math.ceil(len(dataset_feff_train)/batch_size)*batch_size)\n",
    "if include_transfer_learning:\n",
    "    domain_train_sampler = WeightedRandomSampler(domain_train_sample_weights, replacement=True,\n",
    "                                                 num_samples=math.ceil(len(dataset_feff_train)/batch_size)*batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn_train_feff_loader = DataLoader(dataset_feff_train, \n",
    "                                  batch_size=batch_size,\n",
    "                                  sampler=cn_train_sampler,\n",
    "                                  num_workers=0, pin_memory=False)\n",
    "if include_transfer_learning:\n",
    "    domain_train_feff_loader = DataLoader(dataset_feff_train, \n",
    "                                          batch_size=batch_size,\n",
    "                                          sampler=domain_train_sampler,\n",
    "                                          num_workers=0, pin_memory=False)\n",
    "\n",
    "    domain_train_xspectra_loader = DataLoader(dataset_xspectra_train, \n",
    "                                              batch_size=math.ceil(len(dataset_xspectra_train)/len(domain_train_feff_loader)),\n",
    "                                              shuffle=True, num_workers=0, pin_memory=False)\n",
    "\n",
    "cn_val_loader = DataLoader(dataset_feff_val, batch_size=batch_size,\n",
    "                           num_workers=0, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodingBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, in_len, out_len, kernel_size=7, stride=2, excitation=4, dropout_rate=0.2):\n",
    "        super(EncodingBlock, self).__init__()\n",
    "        if in_channels > 1:\n",
    "            self.bn1 = nn.BatchNorm1d(in_channels, affine=False)    \n",
    "        else:\n",
    "            self.bn1 = None\n",
    "        self.relu1 = nn.PReLU(num_parameters=out_channels, init=0.01)\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size, padding=(kernel_size-1)//2, padding_mode='replicate')\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels, affine=False)\n",
    "        self.relu2 = nn.PReLU(num_parameters=out_channels, init=0.01)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=kernel_size, padding=(kernel_size-1)//2, stride=stride)\n",
    "        \n",
    "        if in_len > 10:\n",
    "            self.dropout_1 = nn.Dropout(p=dropout_rate)\n",
    "        else:\n",
    "            self.dropout_1 = None\n",
    "        self.fc1 = nn.Linear(in_len, excitation)\n",
    "        self.relu_excit_1 = nn.PReLU(num_parameters=in_channels, init=0.01)\n",
    "        self.fc2 = nn.Linear(excitation, out_len)\n",
    "        self.relu_excit_2 = nn.PReLU(num_parameters=in_channels, init=0.01)\n",
    "        if in_channels != out_channels:\n",
    "            self.bn_excit = nn.BatchNorm1d(in_channels, affine=False)\n",
    "            self.relu_excit_3 = nn.PReLU(num_parameters=out_channels, init=0.01)\n",
    "            self.conv_excit = nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=1, groups=math.gcd(in_channels, out_channels))\n",
    "        else:\n",
    "            self.bn_excit = None\n",
    "            self.relu_excit_3 = None\n",
    "            self.conv_excit = None        \n",
    "        \n",
    "        if stride > 1 or (in_channels != out_channels):\n",
    "            self.conv_short = nn.Conv1d(in_channels, out_channels, kernel_size=stride, stride=stride, groups=math.gcd(in_channels, out_channels))\n",
    "            self.relu_short = nn.PReLU(num_parameters=out_channels, init=0.01)\n",
    "        else:\n",
    "            self.conv_short = None\n",
    "            \n",
    "        self.fc_domain = nn.Linear(1, excitation*in_channels)\n",
    "\n",
    "        \n",
    "    def forward(self, x, domain=0):\n",
    "        \n",
    "        if self.bn1 is not None:\n",
    "            out = self.bn1(x)  \n",
    "        else:\n",
    "            out = x\n",
    "        residual = out\n",
    "        out = self.conv1(out)\n",
    "        out = self.relu1(out)\n",
    "        \n",
    "        out = self.bn2(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.relu2(out)\n",
    "        \n",
    "        if self.conv_short is not None:\n",
    "            res = self.conv_short(residual)\n",
    "            res = self.relu_short(res)\n",
    "        else:\n",
    "            res = residual\n",
    "        \n",
    "        if self.dropout_1 is not None:\n",
    "            excit = self.dropout_1(residual)\n",
    "        else:\n",
    "            excit = residual\n",
    "        excit = self.fc1(excit)\n",
    "        excit = self.relu_excit_1(excit)\n",
    "        \n",
    "        domain = torch.full([excit.size()[0], 1], fill_value=domain, requires_grad=False, dtype=excit.dtype, device=excit.device)\n",
    "        domain_corr = self.fc_domain(domain).reshape(*excit.size())\n",
    "        excit += domain_corr\n",
    "        \n",
    "        excit = self.fc2(excit)\n",
    "        excit = self.relu_excit_2(excit)\n",
    "        if self.conv_excit is not None:\n",
    "            excit = self.bn_excit(excit)\n",
    "            excit = self.conv_excit(excit)\n",
    "            excit = self.relu_excit_3(excit)\n",
    "            \n",
    "        out = out + res + excit\n",
    "        return out\n",
    "\n",
    "t = torch.ones((32, 1, 256))\n",
    "eb = EncodingBlock(1, 2, 256, 128, kernel_size=11, stride=2)\n",
    "eb(t).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecodingBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, in_len, excitation=4, dropout_rate=0.2):\n",
    "        super(DecodingBlock, self).__init__()\n",
    "        out_len = in_len * 4\n",
    "        self.bn1 = nn.BatchNorm1d(in_channels, affine=False)\n",
    "        self.relu1 = nn.PReLU(num_parameters=out_channels, init=0.01)\n",
    "        self.conv1 = nn.ConvTranspose1d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels, affine=False)\n",
    "        self.relu2 = nn.PReLU(num_parameters=out_channels, init=0.01)\n",
    "        self.conv2 = nn.ConvTranspose1d(out_channels, out_channels, kernel_size=2, stride=2)\n",
    "        \n",
    "        if in_len > 10:\n",
    "            self.dropout_1 = nn.Dropout(p=dropout_rate)\n",
    "        else:\n",
    "            self.dropout_1 = None\n",
    "        self.fc1 = nn.Linear(in_len, excitation)\n",
    "        self.relu_excit_1 = nn.PReLU(num_parameters=in_channels, init=0.01)\n",
    "        self.fc2 = nn.Linear(excitation, out_len)\n",
    "        self.relu_excit_2 = nn.PReLU(num_parameters=in_channels, init=0.01)\n",
    "        if in_channels != out_channels:\n",
    "            self.bn_excit = nn.BatchNorm1d(in_channels, affine=False)\n",
    "            self.relu_excit_3 = nn.PReLU(num_parameters=out_channels, init=0.01)\n",
    "            self.conv_excit = nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=1, groups=math.gcd(in_channels, out_channels))\n",
    "        else:\n",
    "            self.bn_excit = None\n",
    "            self.relu_excit_3 = None\n",
    "            self.conv_excit = None\n",
    "               \n",
    "        self.conv_short = nn.ConvTranspose1d(in_channels, out_channels, kernel_size=4, stride=4, groups=math.gcd(in_channels, out_channels))\n",
    "        self.relu_short = nn.PReLU(num_parameters=out_channels, init=0.01)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.bn1(x)\n",
    "        residual = out\n",
    "        out = self.conv1(out)\n",
    "        out = self.relu1(out)\n",
    "        \n",
    "        out = self.bn2(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.relu2(out)\n",
    "\n",
    "        res = self.conv_short(residual)\n",
    "        res = self.relu_short(res)\n",
    "        \n",
    "        if self.dropout_1 is not None:\n",
    "            excit = self.dropout_1(residual)\n",
    "        else:\n",
    "            excit = residual\n",
    "        excit = self.fc1(excit)\n",
    "        excit = self.relu_excit_1(excit)\n",
    "        excit = self.fc2(excit)\n",
    "        excit = self.relu_excit_2(excit)\n",
    "        if self.conv_excit is not None:\n",
    "            excit = self.bn_excit(excit)\n",
    "            excit = self.conv_excit(excit)\n",
    "            excit = self.relu_excit_3(excit)\n",
    "            \n",
    "        out = out + res + excit\n",
    "        return out\n",
    "\n",
    "t = torch.ones((32, 14, 1))\n",
    "eb = DecodingBlock(14, 8, 1, excitation=1)\n",
    "eb(t).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianSmoothing(nn.Module):\n",
    "    def __init__(self, channels, kernel_size, sigma, dim=2, device='cpu'):\n",
    "        super(GaussianSmoothing, self).__init__()\n",
    "        if isinstance(kernel_size, numbers.Number):\n",
    "            kernel_size = [kernel_size] * dim\n",
    "        if isinstance(sigma, numbers.Number):\n",
    "            sigma = [sigma] * dim\n",
    "\n",
    "        # The gaussian kernel is the product of the\n",
    "        # gaussian function of each dimension.\n",
    "        kernel = 1\n",
    "        meshgrids = torch.meshgrid(\n",
    "            [\n",
    "                torch.arange(size, dtype=torch.float32)\n",
    "                for size in kernel_size\n",
    "            ]\n",
    "        )      \n",
    "        for size, std, mgrid in zip(kernel_size, sigma, meshgrids):\n",
    "            mean = (size - 1) / 2\n",
    "            kernel *= 1 / (std * math.sqrt(2 * math.pi)) * \\\n",
    "                      torch.exp(-((mgrid - mean) / std) ** 2 / 2)\n",
    "\n",
    "        # Make sure sum of values in gaussian kernel equals 1.\n",
    "        kernel = kernel / torch.sum(kernel)\n",
    "\n",
    "        # Reshape to depthwise convolutional weight\n",
    "        kernel = kernel.view(1, 1, *kernel.size())\n",
    "        kernel = kernel.repeat(channels, *[1] * (kernel.dim() - 1))\n",
    "\n",
    "        self.register_buffer('weight', kernel.to(device))\n",
    "        self.groups = channels \n",
    "        \n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Apply gaussian filter to input.\n",
    "        Arguments:\n",
    "            input (torch.Tensor): Input to apply gaussian filter on.\n",
    "        Returns:\n",
    "            filtered (torch.Tensor): Filtered output.\n",
    "        \"\"\"\n",
    "        \n",
    "        if len(input.size()) - 2 == 1:\n",
    "            conv = nn.functional.conv1d\n",
    "        elif len(input.size()) - 2 == 2:\n",
    "            conv = nn.functional.conv2d\n",
    "        elif len(input.size()) - 2 == 3:\n",
    "            conv = nn.functional.conv3d\n",
    "        else:\n",
    "            raise RuntimeError(\n",
    "                'Only 1, 2 and 3 dimensions are supported. Received {}.'.format(dim)\n",
    "            )\n",
    "        return conv(input, weight=self.weight, groups=self.groups)\n",
    "\n",
    "t = torch.rand((3, 256))\n",
    "sns.set_palette(\"husl\", t.size()[0]*2)\n",
    "for spec in t:\n",
    "    plt.plot(spec, lw=1.0)\n",
    "    \n",
    "sm = GaussianSmoothing(channels=1, kernel_size=17, sigma=3.0, dim=1)\n",
    "t = t.unsqueeze(dim=1)\n",
    "t = nn.functional.pad(t, (8, 8), mode='replicate')\n",
    "t = sm(t).squeeze(dim=1)\n",
    "plt.figure()\n",
    "for spec in t:\n",
    "    plt.plot(spec, lw=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mySequential(nn.Sequential):\n",
    "    def forward(self, spec, domain):\n",
    "        output = spec\n",
    "        for module in self._modules.values():\n",
    "            output = module(output, domain)\n",
    "        return output\n",
    "    \n",
    "class Q_net(nn.Module):\n",
    "    ''' front end part of discriminator and Q'''\n",
    "\n",
    "    def __init__(self, dropout_rate=0.2, nclasses=12, nstyle=2):\n",
    "        super(Q_net, self).__init__()\n",
    "\n",
    "        self.main = mySequential(\n",
    "            EncodingBlock(in_channels=1, out_channels=4, in_len=256, out_len=128, kernel_size=11, stride=2, excitation=4, dropout_rate=dropout_rate),\n",
    "            EncodingBlock(in_channels=4, out_channels=4, in_len=128, out_len=64, kernel_size=11, stride=2, excitation=4, dropout_rate=dropout_rate),\n",
    "            EncodingBlock(in_channels=4, out_channels=4, in_len=64, out_len=32, kernel_size=7, stride=2, excitation=2, dropout_rate=dropout_rate),\n",
    "            EncodingBlock(in_channels=4, out_channels=4, in_len=32, out_len=16, kernel_size=7, stride=2, excitation=2, dropout_rate=dropout_rate),\n",
    "            EncodingBlock(in_channels=4, out_channels=4, in_len=16, out_len=8, kernel_size=5, stride=2, excitation=1, dropout_rate=dropout_rate) \n",
    "        )\n",
    "        self.lin1 = nn.Linear(32, nclasses)\n",
    "        self.lin3 = nn.Linear(32, nstyle)\n",
    "\n",
    "    def forward(self, spec, domain=0):\n",
    "        batch_size = spec.size()[0]\n",
    "        output = spec.unsqueeze(dim=1)\n",
    "        output = self.main(output, domain)\n",
    "        output = output.reshape(batch_size, 32)\n",
    "        \n",
    "        z_gauss = self.lin3(output)\n",
    "        y = nn.functional.softmax(self.lin1(output), dim=1)\n",
    "        \n",
    "        return z_gauss, y\n",
    "    \n",
    "t = torch.ones((64, 256))\n",
    "eb = Q_net()\n",
    "[x.size() for x in eb(t)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class P_net(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout_rate=0.2,nclasses=12, nstyle=2, gau_kernel_size=11, sigma=2.0, device='cpu'):\n",
    "        super(P_net, self).__init__()\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            DecodingBlock(in_channels=nclasses+nstyle, out_channels=8, in_len=1, excitation=1, dropout_rate=dropout_rate), \n",
    "            DecodingBlock(in_channels=8, out_channels=4, in_len=4, excitation=2, dropout_rate=dropout_rate), \n",
    "            DecodingBlock(in_channels=4, out_channels=4, in_len=16, excitation=2, dropout_rate=dropout_rate), \n",
    "            DecodingBlock(in_channels=4, out_channels=4, in_len=64, excitation=4, dropout_rate=dropout_rate), \n",
    "            EncodingBlock(in_channels=4, out_channels=4, in_len=256, out_len=256, kernel_size=11, stride=1, excitation=2, dropout_rate=dropout_rate),\n",
    "            EncodingBlock(in_channels=4, out_channels=4, in_len=256, out_len=256, kernel_size=11, stride=1, excitation=2, dropout_rate=dropout_rate),\n",
    "            EncodingBlock(in_channels=4, out_channels=2, in_len=256, out_len=256, kernel_size=11, stride=1, excitation=2, dropout_rate=dropout_rate),\n",
    "            EncodingBlock(in_channels=2, out_channels=2, in_len=256, out_len=256, kernel_size=11, stride=1, excitation=2, dropout_rate=dropout_rate),\n",
    "            EncodingBlock(in_channels=2, out_channels=2, in_len=256, out_len=256, kernel_size=11, stride=1, excitation=2, dropout_rate=dropout_rate),\n",
    "            nn.BatchNorm1d(2, affine=False),\n",
    "            nn.Conv1d(2, 1, kernel_size=1, stride=1),\n",
    "            nn.Softplus(beta=2)   #,\n",
    "            #nn.ReplicationPad1d(padding=(gau_kernel_size-1)//2),\n",
    "            #GaussianSmoothing(channels=1, kernel_size=gau_kernel_size, sigma=sigma, dim=1, device=device)\n",
    "        )\n",
    "        \n",
    "        self.nclasses = nclasses\n",
    "        self.nstyle = nstyle\n",
    "\n",
    "    def forward(self, z_gauss, y):\n",
    "        assert z_gauss.size()[1] == self.nstyle\n",
    "        assert y.size()[1] == self.nclasses\n",
    "        x = torch.cat([z_gauss, y], dim=1)\n",
    "        x = x.unsqueeze(dim=2)\n",
    "        spec = self.main(x)\n",
    "        spec = spec.squeeze(dim=1)\n",
    "        return spec\n",
    "    \n",
    "    \n",
    "tz, ty = torch.ones(32, 2), torch.ones(32, 12)\n",
    "eb = P_net()\n",
    "eb(tz, ty).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReverseLayerF(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, alpha):\n",
    "        #ctx.save_for_backward(x)\n",
    "        ctx.alpha = alpha\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):  \n",
    "        grad_input = grad_output.clone()\n",
    "        grad_input = grad_output.neg() * ctx.alpha\n",
    "        return grad_input, None\n",
    "    \n",
    "    \n",
    "if include_transfer_learning:    \n",
    "    class Domain_classifier_net(nn.Module):\n",
    "        def __init__(self, encoder, hiden_size=50, dropout_rate=0.2, nclasses=12, nstyle=2):\n",
    "            super(Domain_classifier_net, self).__init__()\n",
    "            self.latent_size = nclasses + nstyle\n",
    "            self.main = nn.Sequential(\n",
    "                nn.Linear(self.latent_size, hiden_size),\n",
    "                nn.PReLU(num_parameters=hiden_size, init=0.01),\n",
    "\n",
    "                nn.BatchNorm1d(hiden_size, affine=False),\n",
    "                nn.Dropout(p=dropout_rate),\n",
    "                nn.Linear(hiden_size, hiden_size),\n",
    "                nn.PReLU(num_parameters=hiden_size, init=0.01),\n",
    "\n",
    "                nn.BatchNorm1d(hiden_size, affine=False),\n",
    "                nn.Dropout(p=dropout_rate),\n",
    "                nn.Linear(hiden_size, hiden_size),\n",
    "                nn.PReLU(num_parameters=hiden_size, init=0.01),\n",
    "\n",
    "                nn.BatchNorm1d(hiden_size, affine=False),\n",
    "                nn.Dropout(p=dropout_rate),\n",
    "                nn.Linear(hiden_size, hiden_size),\n",
    "                nn.PReLU(num_parameters=hiden_size, init=0.01),\n",
    "\n",
    "                nn.BatchNorm1d(hiden_size, affine=False),\n",
    "                nn.Dropout(p=dropout_rate),\n",
    "                nn.Linear(hiden_size, 2),\n",
    "                nn.LogSoftmax(dim=1)\n",
    "            )\n",
    "            self.encoder = encoder\n",
    "\n",
    "\n",
    "        def forward(self, x, alpha, domain):\n",
    "            batch_size = x.size()[0]\n",
    "            feature = self.encoder(x, domain)\n",
    "            feature = torch.cat(feature, dim=1)\n",
    "            reverse_feature = ReverseLayerF.apply(feature, alpha)\n",
    "            reverse_feature = reverse_feature.reshape(batch_size, self.latent_size)\n",
    "            domain_output = self.main(reverse_feature)\n",
    "            return domain_output\n",
    "\n",
    "    t = torch.ones((64, 256))\n",
    "    eb = Domain_classifier_net(Q_net())\n",
    "    print(eb(t, 0.3, 0).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D_net_gauss(nn.Module):\n",
    "    def __init__(self, hiden_size=50, dropout_rate=0.2, nstyle=2):\n",
    "        super(D_net_gauss, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(nstyle, hiden_size),\n",
    "            nn.PReLU(num_parameters=hiden_size, init=0.01),\n",
    "            \n",
    "            nn.BatchNorm1d(hiden_size, affine=False),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(hiden_size, hiden_size),\n",
    "            nn.PReLU(num_parameters=hiden_size, init=0.01),\n",
    "            \n",
    "            nn.BatchNorm1d(hiden_size, affine=False),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(hiden_size, hiden_size),\n",
    "            nn.PReLU(num_parameters=hiden_size, init=0.01),\n",
    "            \n",
    "            nn.BatchNorm1d(hiden_size, affine=False),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(hiden_size, hiden_size),\n",
    "            nn.PReLU(num_parameters=hiden_size, init=0.01),\n",
    "            \n",
    "            nn.BatchNorm1d(hiden_size, affine=False),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(hiden_size, 2),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "        self.nstyle = nstyle\n",
    "\n",
    "\n",
    "    def forward(self, x, alpha):\n",
    "        reverse_feature = ReverseLayerF.apply(x, alpha)\n",
    "        out = self.main(reverse_feature)\n",
    "        return out\n",
    "\n",
    "t = torch.ones((64, 2))\n",
    "eb = D_net_gauss()\n",
    "eb(t, 0.3).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeDualAAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FakeDualAAE, self).__init__()\n",
    "        self.q = Q_net()\n",
    "        self.p = P_net()\n",
    "        self.d = D_net_gauss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        z, y = self.q(x)\n",
    "        x2 = self.p(z, y)\n",
    "        is_gau = self.d(z, 0.3)\n",
    "        return x2, is_gau\n",
    "    \n",
    "t = torch.ones((64, 256))\n",
    "eb = FakeDualAAE()\n",
    "eb(t)[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class Trainer:\n",
    "\n",
    "    def __init__(self, Q, P, D_gauss, Dann, device, cn_train_feff_loader, cn_val_loader, \n",
    "                 domain_train_feff_loader, domain_train_xspectra_loader, \n",
    "                 val_cn_weights, base_lr=0.0001, nclasses=12, nstyle=2, batch_size=111, max_epoch=300, \n",
    "                 tb_logdir=\"runs\", zero_conc_thresh=0.05):\n",
    "\n",
    "        self.q = Q.to(device)\n",
    "        self.p = P.to(device)\n",
    "        self.d = D_gauss.to(device)\n",
    "        if include_transfer_learning:\n",
    "            self.dann = Dann.to(device)\n",
    "            self.domain_train_feff_loader = domain_train_feff_loader\n",
    "            self.domain_train_xspectra_loader = domain_train_xspectra_loader\n",
    "        \n",
    "        self.nclasses = nclasses\n",
    "        self.nstyle = nstyle\n",
    "        \n",
    "        self.val_cn_weights = torch.tensor(val_cn_weights,  dtype=torch.float, device=device)\n",
    "        self.batch_size = batch_size\n",
    "        self.max_epoch = max_epoch\n",
    "        self.base_lr = base_lr\n",
    "        self.device = device\n",
    "        self.cn_train_feff_loader = cn_train_feff_loader\n",
    "        self.cn_val_loader = cn_val_loader\n",
    "        \n",
    "        self.noise_test_range = (-2, 2)\n",
    "        self.ntest_per_spectra = 10\n",
    "        self.zero_conc_thresh = zero_conc_thresh\n",
    "        gau_kernel_size = 17\n",
    "        self.gaussian_smoothing = GaussianSmoothing(channels=1, kernel_size=gau_kernel_size, sigma=3.0, dim=1, device=device).to(device)\n",
    "        self.padding4smooth = nn.ReplicationPad1d(padding=(gau_kernel_size-1)//2).to(device)\n",
    "        \n",
    "        self.tb_writer = SummaryWriter(log_dir=tb_logdir)\n",
    "        \n",
    "        example_spec = iter(cn_train_feff_loader).next()[0]\n",
    "        self.tb_writer.add_graph(FakeDualAAE(), example_spec)\n",
    "\n",
    "    def sample_categorical(self):\n",
    "        '''\n",
    "         Sample from a categorical distribution\n",
    "         of size batch_size and # of classes n_classes\n",
    "         return: torch.autograd.Variable with the sample\n",
    "        '''\n",
    "        idx = np.random.randint(0, self.nclasses, self.batch_size)\n",
    "        cat = np.eye(self.nclasses)[idx].astype('float32')\n",
    "        cat = torch.tensor(cat, requires_grad=False, device=self.device)\n",
    "        return cat, idx\n",
    "\n",
    "    def zerograd(self):\n",
    "        self.q.zero_grad()\n",
    "        self.p.zero_grad()\n",
    "        self.d.zero_grad()\n",
    "        if include_transfer_learning:\n",
    "            self.dann.zero_grad()\n",
    "            \n",
    "    def d_entropy1(self, y):\n",
    "        y1 = y.mean(dim=0) \n",
    "        y2 = torch.sum(-y1*torch.log(y1+1e-5))\n",
    "        return y2   \n",
    "        \n",
    "    def d_entropy2(self, y):\n",
    "        y1 = -y*torch.log(y+1e-5)\n",
    "        y2 = torch.sum(y1)/self.batch_size\n",
    "        return y2      \n",
    "        \n",
    "    def get_cluster_idx(self, Y_pred):\n",
    "        return Y_pred.argmax(dim=1).cpu()\n",
    "    \n",
    "    def get_cluster_plot(self, spec_list, nsub=3):\n",
    "        assert spec_list.shape[0] == self.nclasses\n",
    "        assert spec_list.shape[1] == self.ntest_per_spectra\n",
    "        fig, ax_list = plt.subplots(self.nclasses//nsub, nsub, sharex=True, sharey=True, figsize=(9, 12))\n",
    "        colors = sns.color_palette(\"husl\", self.ntest_per_spectra)\n",
    "        for i, (sl, ax) in enumerate(zip(spec_list, ax_list.ravel())):\n",
    "            for spec, color in zip(sl, colors):\n",
    "                ax.plot(spec, lw=1.5, c=color)\n",
    "                if i % 3 == 0:\n",
    "                    ax.set_ylabel(f\"{i//n_subclasses + 3} Folds Coordinated\")\n",
    "                if i >= (n_coord_num-1) *n_subclasses:\n",
    "                    ax.set_xlabel(f\"Subclass {i%3 + 1}\")    \n",
    "        title = \"All Classes and Styles\"\n",
    "        fig.suptitle(title, y=0.91)\n",
    "        return fig\n",
    "    \n",
    "    def get_style_distribution_plot(self, z):\n",
    "        fig, ax_list = plt.subplots(self.nstyle, 1, sharex=True, sharey=True, figsize=(9, 12))\n",
    "        for istyle, ax in zip(range(self.nstyle), ax_list):\n",
    "            sns.distplot(z[:, istyle], kde=False, color='blue', bins=np.arange(-3.0, 3.01, 0.2),\n",
    "                         ax=ax)\n",
    "        return fig\n",
    "            \n",
    "\n",
    "    def train(self):\n",
    "        \n",
    "        #loss function\n",
    "        mse_dis = nn.MSELoss().to(self.device)\n",
    "        criterionQ_dis = nn.NLLLoss().to(self.device)\n",
    "        bce_loss = nn.BCELoss().to(self.device)\n",
    "        nll_loss = nn.NLLLoss().to(self.device)\n",
    "        \n",
    "        \n",
    "        solver_lr_ratio = {\n",
    "            \"RE\": lr_ratio_Reconn,\n",
    "            \"I\": lr_ratio_Mutual,\n",
    "            \"Smooth\": lr_ratio_Smooth,\n",
    "            \"Cat\": lr_ratio_Supervise,\n",
    "            \"G\": lr_ratio_Style,\n",
    "            \"h\": lr_ratio_CR,    \n",
    "        }\n",
    "        if include_transfer_learning:\n",
    "            solver_lr_ratio[\"dann\"] = lr_ratio_domain\n",
    "            \n",
    "        RE_solver = optim.AdamW([{'params':self.q.parameters()}, {'params':self.p.parameters()}], lr=solver_lr_ratio[\"RE\"]*self.base_lr)\n",
    "        I_solver = optim.AdamW([{'params':self.q.parameters()}, {'params':self.p.parameters()}], lr=solver_lr_ratio[\"I\"]*self.base_lr)\n",
    "        Smooth_solver = optim.AdamW([{'params':self.p.parameters()}], lr=solver_lr_ratio[\"Smooth\"]*self.base_lr)\n",
    "        Cat_solver = optim.AdamW([{'params':self.q.parameters()}], lr=solver_lr_ratio[\"Cat\"]*self.base_lr)\n",
    "        G_solver = optim.AdamW([{'params':self.d.parameters()}, {'params':self.q.parameters()}], lr=solver_lr_ratio[\"G\"]*self.base_lr)\n",
    "        h_solver = optim.AdamW([{'params':self.q.parameters()}], lr=solver_lr_ratio[\"h\"]*self.base_lr)\n",
    "        if include_transfer_learning:\n",
    "            Dann_solver =  optim.AdamW([{'params':self.dann.parameters()}], lr=solver_lr_ratio[\"dann\"]*self.base_lr)\n",
    "        \n",
    "        sol_list = [RE_solver, I_solver, Smooth_solver, Cat_solver, G_solver, h_solver]\n",
    "        if include_transfer_learning:\n",
    "            sol_list.append(Dann_solver)\n",
    "        schedulers = [ReduceLROnPlateau(sol, factor=sch_factor, patience=sch_patience, cooldown=0, threshold=0.01, verbose=True)\n",
    "                      for sol in sol_list]\n",
    "        \n",
    "        \n",
    "        # fixed random variables, for plot spectra\n",
    "        Idx = np.arange(self.nclasses).repeat(self.ntest_per_spectra)\n",
    "        one_hot = np.zeros((self.nclasses * self.ntest_per_spectra, self.nclasses))\n",
    "        one_hot[range(self.nclasses * self.ntest_per_spectra), Idx] = 1\n",
    "\n",
    "        c = np.linspace(*self.noise_test_range, self.ntest_per_spectra).reshape(1,-1)\n",
    "        c = np.repeat(c, self.nclasses, 0).reshape(-1, 1)\n",
    "        c2 = np.hstack([np.zeros_like(c)] * (self.nstyle-1) + [c])\n",
    "\n",
    "        dis_c = torch.tensor(one_hot, dtype=torch.float, device=self.device, requires_grad=False)\n",
    "        con_c = torch.tensor(c2, dtype=torch.float, device=self.device, requires_grad=False)\n",
    "        \n",
    "        if include_transfer_learning:\n",
    "                assert len(self.cn_train_feff_loader) == len(self.domain_train_feff_loader)\n",
    "                assert len(self.cn_train_feff_loader) == len(self.domain_train_xspectra_loader)\n",
    "                \n",
    "        #train network\n",
    "        last_best = 0.0\n",
    "        chkpt_dir = \"checkpoints\"\n",
    "        if not os.path.exists(chkpt_dir):\n",
    "            os.makedirs(chkpt_dir, exist_ok=True)\n",
    "        best_chk = None\n",
    "        for epoch in tqdm(range(self.max_epoch), desc=\"Cluster\"):            \n",
    "            # Set the networks in train mode (apply dropout when needed)\n",
    "            self.q.train()\n",
    "            self.p.train()\n",
    "            self.d.train()\n",
    "            if include_transfer_learning:\n",
    "                self.dann.train()\n",
    "            # Loop through the labeled and unlabeled dataset getting one batch of samples from each\n",
    "            # The batch size has to be a divisor of the size of the dataset or it will return\n",
    "            # invalid samples\n",
    "            \n",
    "            iterator_cn_train = iter(self.cn_train_feff_loader)\n",
    "            if include_transfer_learning:\n",
    "                iterator_domain_feff = iter(self.domain_train_feff_loader)\n",
    "                iterator_damain_xspectra = iter(self.domain_train_xspectra_loader)\n",
    "            \n",
    "            for _ in range(len(self.cn_train_feff_loader)):\n",
    "                spec_in, cn_in = next(iterator_cn_train)\n",
    "                if include_transfer_learning:\n",
    "                    spec_src, _ = next(iterator_domain_feff)\n",
    "                    spec_target, _ = next(iterator_damain_xspectra)\n",
    "                alpha = (2. / (1. + np.exp(-1.0E4 / alpha_flat_step * epoch/self.max_epoch)) - 1) * alpha_limit\n",
    "                \n",
    "                zero_conc_selector = (cn_in < self.zero_conc_thresh)\n",
    "                zero_conc_selector = zero_conc_selector.unsqueeze(dim=2)\n",
    "                zero_conc_selector = zero_conc_selector.repeat(1, 1, self.nclasses//cn_in.size()[1])\n",
    "                zero_conc_selector = zero_conc_selector.resize(cn_in.size()[0], self.nclasses)\n",
    "                pure_selector = (cn_in.max(dim=-1).values > 1.0 - self.zero_conc_thresh)\n",
    "        \n",
    "                spec_in = spec_in.to(self.device)\n",
    "                if include_transfer_learning:\n",
    "                    spec_src = spec_src.to(self.device)\n",
    "                    spec_target = spec_target.to(self.device)\n",
    "                pure_selector = pure_selector.to(self.device)\n",
    "                zero_conc_selector = zero_conc_selector.to(self.device)\n",
    "                bce_eps = torch.full_like(zero_conc_selector[zero_conc_selector], fill_value=1.0E-3, dtype=torch.float, device=self.device)\n",
    "                \n",
    "                # Init gradients\n",
    "                self.zerograd()\n",
    "        \n",
    "                #Domain loss\n",
    "                if include_transfer_learning:\n",
    "                    comp_domain_label = torch.zeros(spec_src.size()[0], dtype=torch.long, requires_grad=False, device=self.device)\n",
    "                    comp_domain_pred = self.dann(spec_src, alpha, 0)\n",
    "\n",
    "                    exp_domain_label = torch.ones(spec_target.size()[0], dtype=torch.long, requires_grad=False, device=self.device)\n",
    "                    exp_domain_pred = self.dann(spec_target, alpha, 1)\n",
    "                    domain_loss = nll_loss(comp_domain_pred, comp_domain_label) + nll_loss(exp_domain_pred, exp_domain_label)\n",
    "                    domain_loss.backward()\n",
    "                    Dann_solver.step()\n",
    "        \n",
    "                # Init gradients\n",
    "                self.zerograd()\n",
    "        \n",
    "                # D loss\n",
    "                z_real_gauss = torch.randn(self.batch_size, self.nstyle, requires_grad=True, device=self.device)\n",
    "                z_fake_gauss, _ = self.q(spec_in)\n",
    "                \n",
    "                real_gauss_label = torch.ones(self.batch_size, dtype=torch.long, requires_grad=False, device=self.device)\n",
    "                real_gauss_pred = self.d(z_real_gauss, alpha)\n",
    "                \n",
    "                fake_guass_lable = torch.zeros(spec_in.size()[0], dtype=torch.long, requires_grad=False, device=self.device)\n",
    "                fake_gauss_pred = self.d(z_fake_gauss, alpha)\n",
    "                       \n",
    "                G_loss = nll_loss(real_gauss_pred, real_gauss_label) + nll_loss(fake_gauss_pred, fake_guass_lable)\n",
    "                G_loss.backward()\n",
    "                G_solver.step()\n",
    "                \n",
    "                \n",
    "                # Init gradients\n",
    "                self.zerograd()\n",
    "        \n",
    "                #H loss\n",
    "                _, y = self.q(spec_in[pure_selector])\n",
    "                h1_loss = self.d_entropy2(y)\n",
    "                h2_loss = -self.d_entropy1(y)\n",
    "                h_loss = 0.5 * h1_loss + h2_loss\n",
    "                h_loss.backward()\n",
    "                h_solver.step()\n",
    "                \n",
    "                # Init gradients\n",
    "                self.zerograd()\n",
    "                _, y = self.q(spec_in)\n",
    "                cat_semisupervise_loss = bce_loss(y[zero_conc_selector], bce_eps)\n",
    "                \n",
    "                cat_semisupervise_loss.backward()\n",
    "                Cat_solver.step()\n",
    "                \n",
    "                # Init gradients\n",
    "                self.zerograd()\n",
    "                \n",
    "                #recon_x\n",
    "                z, y = self.q(spec_in)\n",
    "                spec_re = self.p(z, y)\n",
    "                \n",
    "                recon_loss = mse_dis(spec_re, spec_in)\n",
    "                recon_loss.backward()\n",
    "                RE_solver.step()\n",
    "                \n",
    "                # Init gradients\n",
    "                self.zerograd()\n",
    "                \n",
    "                #recon y and d\n",
    "                y, idx = self.sample_categorical()\n",
    "                z = torch.randn(self.batch_size, self.nstyle, requires_grad=False, device=self.device)\n",
    "                target = torch.tensor(idx, dtype=torch.long, requires_grad=False, device=self.device)\n",
    "                \n",
    "                X_sample = self.p(z, y)\n",
    "                z_recon, y_recon = self.q(X_sample)\n",
    "                \n",
    "                I_loss = criterionQ_dis(torch.log(y_recon), target) + mse_dis(z_recon[:,:-1], z[:, :-1])\n",
    "                \n",
    "                I_loss.backward()\n",
    "                I_solver.step()\n",
    "                \n",
    "                # Init gradients\n",
    "                self.zerograd()\n",
    "                \n",
    "                X_sample = self.p(z, y)\n",
    "                # smoothed regulation\n",
    "                X_sample_padded = self.padding4smooth(X_sample.unsqueeze(dim=1))\n",
    "                spec_smoothed = self.gaussian_smoothing(X_sample_padded).squeeze(dim=1)\n",
    "                Smooth_loss = mse_dis(X_sample, spec_smoothed)\n",
    "                \n",
    "                Smooth_loss.backward()\n",
    "                Smooth_solver.step()\n",
    "                \n",
    "                # Init gradients\n",
    "                self.zerograd()\n",
    "                \n",
    "                # record losses   \n",
    "                loss_dict = {\n",
    "                    'recon_loss': recon_loss.item(),\n",
    "                    'I_loss': I_loss.item(),   \n",
    "                    'Smooth': Smooth_loss.item()\n",
    "                }\n",
    "                self.tb_writer.add_scalars(\"Recon/train\", loss_dict, global_step=epoch)\n",
    "                loss_dict = {\n",
    "                    'h_loss': h_loss.item()\n",
    "                }\n",
    "                self.tb_writer.add_scalars(\"CR/train\", loss_dict, global_step=epoch)\n",
    "                if include_transfer_learning:\n",
    "                    loss_dict = {\n",
    "                        'domain_loss': domain_loss.item()\n",
    "                    }\n",
    "                    self.tb_writer.add_scalars(\"Domain/train\", loss_dict, global_step=epoch)\n",
    "                loss_dict = { \n",
    "                    'cat_loss': cat_semisupervise_loss.item()\n",
    "                }\n",
    "                self.tb_writer.add_scalars(\"Supervise/train\", loss_dict, global_step=epoch)\n",
    "                loss_dict = {\n",
    "                    'G_loss': G_loss.item()       \n",
    "                }\n",
    "                self.tb_writer.add_scalars(\"Adversarial/train\", loss_dict, global_step=epoch)\n",
    "            \n",
    "            \n",
    "            \n",
    "            self.q.eval()\n",
    "            self.p.eval()\n",
    "            self.d.eval()\n",
    "            if include_transfer_learning:\n",
    "                self.dann.eval()\n",
    "            spec_in, cn_in = [torch.cat(x, dim=0) for x in zip(*list(self.cn_val_loader))]\n",
    "            spec_in = spec_in.to(self.device)\n",
    "            cn_in = cn_in.to(self.device)\n",
    "            z, y = self.q(spec_in)\n",
    "            spec_re = self.p(z, y)\n",
    "            tw =  cn_in @ self.val_cn_weights\n",
    "            tw /= tw.sum()\n",
    "            spec_diff = ((spec_re - spec_in)**2).mean(dim=1)\n",
    "            recon_loss = (spec_diff * tw).sum()\n",
    "            loss_dict = {\n",
    "                'recon_loss': recon_loss.item()\n",
    "            }\n",
    "            self.tb_writer.add_scalars(\"Recon/val\", loss_dict, global_step=epoch) \n",
    "            \n",
    "            class_probs = y.detach().cpu().numpy()\n",
    "            class_pred = class_probs.argmax(axis=-1)//n_subclasses\n",
    "            class_true = cn_in.detach().cpu().numpy().argmax(axis=-1)\n",
    "            cat_accuracy = f1_score(class_true, class_pred, average='weighted')\n",
    "            \n",
    "            class_sum_pred = class_probs.reshape(class_probs.shape[0], cn_in.size()[1], n_subclasses).sum(axis=1).argmax(axis=-1)\n",
    "            cat_sum_accuracy = f1_score(class_true, class_sum_pred, average='weighted')\n",
    "            \n",
    "            loss_dict = {\n",
    "                'Max Divid': cat_accuracy,\n",
    "                'Group Sum': cat_sum_accuracy\n",
    "            }\n",
    "            self.tb_writer.add_scalars(\"F1 Score/val\", loss_dict, global_step=epoch)\n",
    "            \n",
    "            pure_selector = (cn_in.max(dim=-1).values > 1.0 - self.zero_conc_thresh)\n",
    "            pure_selector = pure_selector.to(self.device)\n",
    "            h1_loss = self.d_entropy2(y[pure_selector])\n",
    "            h2_loss = -self.d_entropy1(y[pure_selector])\n",
    "            h_loss = 0.5 * h1_loss + h2_loss   \n",
    "            loss_dict = {\n",
    "                    'h_loss': h_loss.item(),       \n",
    "            }\n",
    "            self.tb_writer.add_scalars(\"CR/val\", loss_dict, global_step=epoch)\n",
    "            \n",
    "            zero_conc_selector = (cn_in < self.zero_conc_thresh)\n",
    "            zero_conc_selector = zero_conc_selector.unsqueeze(dim=2)\n",
    "            zero_conc_selector = zero_conc_selector.repeat(1, 1, self.nclasses//cn_in.size()[1])\n",
    "            zero_conc_selector = zero_conc_selector.resize(cn_in.size()[0], self.nclasses)\n",
    "\n",
    "            zero_conc_selector = zero_conc_selector.to(self.device)\n",
    "            bce_eps = torch.full_like(zero_conc_selector[zero_conc_selector], fill_value=1.0E-3, dtype=torch.float, device=self.device)\n",
    "            zero_conc_selector = zero_conc_selector.to(self.device)\n",
    "            bce_eps = torch.full_like(zero_conc_selector[zero_conc_selector], fill_value=1.0E-3, dtype=torch.float, device=self.device)\n",
    "            cat_semisupervise_loss = bce_loss(y[zero_conc_selector], bce_eps)\n",
    "            \n",
    "            loss_dict = { \n",
    "                'cat_loss': cat_semisupervise_loss.item()\n",
    "            }\n",
    "            self.tb_writer.add_scalars(\"Supervise/val\", loss_dict, global_step=epoch)\n",
    "            \n",
    "            z_fake_gauss = z\n",
    "            z_real_gauss = torch.randn_like(z, requires_grad=True, device=self.device)\n",
    "\n",
    "            real_gauss_label = torch.ones(spec_in.size()[0], dtype=torch.long, requires_grad=False, device=self.device)\n",
    "            real_gauss_pred = self.d(z_real_gauss, alpha)\n",
    "\n",
    "            fake_guass_lable = torch.zeros(spec_in.size()[0], dtype=torch.long, requires_grad=False, device=self.device)\n",
    "            fake_gauss_pred = self.d(z_fake_gauss, alpha)\n",
    "\n",
    "            G_loss = nll_loss(real_gauss_pred, real_gauss_label) + nll_loss(fake_gauss_pred, fake_guass_lable)\n",
    "\n",
    "            loss_dict = {\n",
    "                'G_loss': G_loss.item()       \n",
    "            }\n",
    "            self.tb_writer.add_scalars(\"Adversarial/val\", loss_dict, global_step=epoch)\n",
    "            \n",
    "            model_dict = {\"Encoder\": self.q, \n",
    "                          \"Decoder\": self.p, \n",
    "                          \"Style Discriminator\": self.d}\n",
    "            if include_transfer_learning:\n",
    "                model_dict[\"Domain Classifier\"] = self.dann\n",
    "            if cat_accuracy > last_best * 1.01:\n",
    "                chk_fn = f\"{chkpt_dir}/epoch_{epoch:06d}_loss_{cat_accuracy:05.4g}.pt\"\n",
    "                torch.save(model_dict, \n",
    "                           chk_fn)\n",
    "                last_best = cat_accuracy\n",
    "                best_chk = chk_fn\n",
    "                \n",
    "            for sch in schedulers:\n",
    "                sch.step(torch.tensor(last_best))\n",
    "                \n",
    "            # plot images\n",
    "            if epoch % 25 == 0:\n",
    "                spec_out = self.p(con_c, dis_c).reshape(self.nclasses, self.ntest_per_spectra, -1).clone().cpu().detach().numpy()\n",
    "                fig = self.get_cluster_plot(spec_out)\n",
    "                self.tb_writer.add_figure(\"Spectra\", fig, global_step=epoch) \n",
    "                \n",
    "                spec_in, cn_in = [torch.cat(x, dim=0) for x in zip(*list(self.cn_val_loader))]\n",
    "                spec_in = spec_in.to(self.device)\n",
    "                cn_in = cn_in.to(self.device)\n",
    "                z, _ = self.q(spec_in)\n",
    "                fig = self.get_style_distribution_plot(z.clone().cpu().detach().numpy())\n",
    "                self.tb_writer.add_figure(\"Style Value Distribution\", fig, global_step=epoch)\n",
    "            \n",
    "        \n",
    "        #save model\n",
    "        model_dict = {\"Encoder\": self.q, \n",
    "                      \"Decoder\": self.p, \n",
    "                      \"Style Discriminator\": self.d}\n",
    "        if include_transfer_learning:\n",
    "            model_dict[\"Domain Classifier\"] = self.dann\n",
    "        torch.save(model_dict, \n",
    "                   'final.pt')\n",
    "        if best_chk is not None:\n",
    "            shutil.copy2(best_chk, 'best.pt')\n",
    "        \n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    print(\"Use GPU\")\n",
    "    for loader in [cn_train_feff_loader, cn_val_loader]:\n",
    "        loader.pin_memory = False\n",
    "    if include_transfer_learning:\n",
    "        domain_train_xspectra_loader.pin_memory = False\n",
    "else:\n",
    "    print(\"Use Slow CPU!\")\n",
    "    \n",
    "device = torch.device(f\"cuda:{igpu}\" if use_cuda else \"cpu\")\n",
    "\n",
    "Q = Q_net(nclasses=n_coord_num*n_subclasses, nstyle=nstyle)\n",
    "P = P_net(nclasses=n_coord_num*n_subclasses, nstyle=nstyle, device=device)\n",
    "D_gauss = D_net_gauss(nstyle=nstyle)\n",
    "if include_transfer_learning:\n",
    "    Dann = Domain_classifier_net(Q, nclasses=n_coord_num*n_subclasses, nstyle=nstyle)\n",
    "else:\n",
    "    Dann = None\n",
    "\n",
    "for i in [Q, P, D_gauss, Dann]:\n",
    "    if i is not None:\n",
    "        i.to(device)\n",
    "        #i.apply(weights_init)\n",
    "\n",
    "if not include_transfer_learning:\n",
    "    domain_train_feff_loader, domain_train_xspectra_loader = None, None\n",
    "\n",
    "trainer = Trainer(Q, P, D_gauss, Dann, device, \n",
    "                  cn_train_feff_loader, cn_val_loader, domain_train_feff_loader, domain_train_xspectra_loader,\n",
    "                  val_cn_weights=cn_sampling_weights, nclasses=n_coord_num*n_subclasses, nstyle=nstyle,\n",
    "                  max_epoch=max_epoch, base_lr=lr)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_info = torch.__config__.parallel_info()\n",
    "print(para_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_grid_plot(decoder):\n",
    "    decoder.eval()\n",
    "    for istyle in range(decoder.nstyle):\n",
    "        nspec_pc = 10\n",
    "        Idx = np.arange(n_coord_num*n_subclasses).repeat(nspec_pc)\n",
    "        one_hot = np.zeros((n_coord_num*n_subclasses*nspec_pc,n_coord_num*n_subclasses))\n",
    "        one_hot[list(range(n_coord_num*n_subclasses*nspec_pc)), Idx] = 1\n",
    "\n",
    "        c = np.linspace(*[-1, 1], n_coord_num*n_subclasses).reshape(1,-1)\n",
    "        c = np.repeat(c, nspec_pc, 0).reshape(-1, 1)\n",
    "        c2 = np.hstack([np.zeros_like(c)] * istyle + [c] + [np.zeros_like(c)]*(decoder.nstyle - istyle - 1))\n",
    "\n",
    "        dis_c = torch.tensor(one_hot, dtype=torch.float, requires_grad=False)\n",
    "        con_c = torch.tensor(c2, dtype=torch.float, requires_grad=False)\n",
    "\n",
    "        spec_out = decoder(con_c, dis_c).reshape(n_coord_num*n_subclasses, nspec_pc, -1).clone().cpu().detach().numpy()\n",
    "        plt.figure()\n",
    "        nsub=n_subclasses\n",
    "        fig, ax_list = plt.subplots(n_coord_num*n_subclasses//nsub, nsub, sharex=True, sharey=True, figsize=(9, 12))\n",
    "        colors = sns.color_palette(\"coolwarm\", nspec_pc)\n",
    "        for i, (sl, ax) in enumerate(zip(spec_out, ax_list.ravel())):\n",
    "            for spec, color in zip(sl, colors):\n",
    "                ax.plot(spec, lw=1.5, c=color)\n",
    "                if i % 3 == 0:\n",
    "                    ax.set_ylabel(f\"{i//n_subclasses + 3} Folds Coordinated\")\n",
    "                if i >= (n_coord_num-1) *n_subclasses:\n",
    "                    ax.set_xlabel(f\"Subclass {i%3 + 1}\")    \n",
    "        title = f\"All Classes and Styles #{istyle}\"\n",
    "        fig.suptitle(title, y=0.91)\n",
    "        if not os.path.exists(\"reports\"):\n",
    "            os.makedirs(\"reports\")\n",
    "        plt.savefig(f\"reports/{title}.pdf\", dpi=600)\n",
    "\n",
    "\n",
    "final_spuncat = torch.load('final.pt', map_location=torch.device('cpu')) \n",
    "cluster_grid_plot(final_spuncat[\"Decoder\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cluster_centers(p, nclasses=n_coord_num*n_subclasses, title='final cluster center'):\n",
    "    p.eval()\n",
    "    nstyle = p.nstyle\n",
    "    one_hot = torch.eye(nclasses)\n",
    "    z = torch.zeros(nclasses, nstyle)\n",
    "    cluster_specs = p(z, one_hot).cpu().detach().numpy()\n",
    "    plt.figure()\n",
    "    sns.set_palette('husl', nclasses)\n",
    "    for spec in cluster_specs:\n",
    "        plt.plot(spec)\n",
    "        \n",
    "    plt.title(title)\n",
    "    if not os.path.exists(\"reports\"):\n",
    "            os.makedirs(\"reports\")\n",
    "    plt.savefig(f'reports/{title}.pdf', dpi=300)\n",
    "    \n",
    "best_spuncat = torch.load('best.pt', map_location=torch.device('cpu'))  \n",
    "plot_cluster_centers(final_spuncat[\"Decoder\"], title='final cluster center')\n",
    "plot_cluster_centers(best_spuncat[\"Decoder\"], title='best cluster center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_confusion_matrix(encoder, ds, title_base):\n",
    "    encoder.eval()\n",
    "    spec_in, cn_in = [torch.stack(x, dim=0) for x in zip(*list(ds))]\n",
    "    _, y = encoder(spec_in)\n",
    "    class_probs = y.detach().cpu().numpy()\n",
    "    class_pred = class_probs.argmax(axis=-1)//n_subclasses\n",
    "    class_true = cn_in.detach().cpu().numpy().argmax(axis=-1)\n",
    "    cat_accuracy = f1_score(class_true, class_pred, average='weighted')\n",
    "    cm = confusion_matrix(class_true, class_pred)\n",
    "    cn_labels = [f'CN{i}' for i in range(4, 4+n_coord_num)]\n",
    "    plt.figure()\n",
    "    sns.set(font_scale=1.4)\n",
    "    sns.heatmap(cm, xticklabels=cn_labels, yticklabels=cn_labels, cmap='Blues', fmt='d', annot=True, lw=1.0)\n",
    "    title = f'{title_base} with F1 Score at {cat_accuracy:.2%}'\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Prediction\")\n",
    "    plt.ylabel(\"True Value\")\n",
    "    if not os.path.exists(\"reports\"):\n",
    "            os.makedirs(\"reports\")\n",
    "    plt.savefig(f'reports/{title_base}.pdf', dpi=300, bbox_inches='tight')\n",
    "    return cm, cat_accuracy\n",
    "\n",
    "compute_confusion_matrix(final_spuncat[\"Encoder\"], dataset_feff_train, title_base=\"Confusion Matrix on FEFF Training Set\"); \n",
    "compute_confusion_matrix(final_spuncat[\"Encoder\"], dataset_feff_val, title_base=\"Confusion Matrix on FEFF Validation Set\");\n",
    "compute_confusion_matrix(final_spuncat[\"Encoder\"], dataset_feff_test, title_base=\"Confusion Matrix on FEFF Test Set\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if include_transfer_learning:\n",
    "    compute_confusion_matrix(final_spuncat[\"Encoder\"], dataset_xspectra_test, title_base=\"Confusion Matrix on XSpectra Target Set\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
